{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERCOT Grid Analytics for Battery Storage & Retail Electricity\n",
    "\n",
    "Analyze ERCOT data for:\n",
    "- **Battery Storage** - Arbitrage opportunities, price spreads, optimal dispatch\n",
    "- **Retail Providers** - Load patterns, price volatility, renewable integration\n",
    "\n",
    "## Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Connected to ERCOT API\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from dotenv import load_dotenv\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from tinygrid import ERCOT, ERCOTAuth, ERCOTAuthConfig\n",
    "\n",
    "# Load credentials\n",
    "load_dotenv(Path.cwd() / \".env\")\n",
    "\n",
    "auth = ERCOTAuth(ERCOTAuthConfig(\n",
    "    username=os.getenv(\"ERCOT_USERNAME\"),\n",
    "    password=os.getenv(\"ERCOT_PASSWORD\"),\n",
    "    subscription_key=os.getenv(\"ERCOT_SUBSCRIPTION_KEY\"),\n",
    "))\n",
    "\n",
    "ercot = ERCOT(auth=auth)\n",
    "print(\"âœ“ Connected to ERCOT API\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Price Spreads - Battery Arbitrage Analysis\n",
    "\n",
    "Batteries profit by charging low, discharging high. \n",
    "\n",
    "**Note:** DAM pricing endpoints may require specific ERCOT API subscriptions. If pricing data isn't available, we'll use system load as a proxy (load and prices are highly correlated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch DAM settlement point prices for December 2024\n",
    "# Use a 3-week window for more comprehensive analysis\n",
    "start_date = datetime(2024, 12, 1)\n",
    "end_date = datetime(2024, 12, 21)  # 3 weeks of data\n",
    "\n",
    "print(f\"Fetching DAM prices from {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "print(f\"Date range: {(end_date - start_date).days + 1} days\\n\")\n",
    "\n",
    "# Fetch data for all major ERCOT hubs\n",
    "# Major hubs: Houston, North, South, West, Pan, BusAvg, HubAvg\n",
    "target_hubs = [\"HB_HOUSTON\", \"HB_NORTH\", \"HB_SOUTH\", \"HB_WEST\", \"HB_PAN\", \"HB_BUSAVG\", \"HB_HUBAVG\"]\n",
    "\n",
    "df_spp_list = []\n",
    "max_pages_per_hub = 50  # Safety limit per hub\n",
    "\n",
    "for hub_idx, hub in enumerate(target_hubs, 1):\n",
    "    print(f\"[{hub_idx}/{len(target_hubs)}] Fetching {hub}...\", end=\" \")\n",
    "    hub_df_list = []\n",
    "    page = 1\n",
    "\n",
    "    while page <= max_pages_per_hub:\n",
    "        try:\n",
    "            spp_data = ercot.get_dam_settlement_point_prices(\n",
    "                delivery_date_from=start_date.strftime(\"%Y-%m-%d\"),\n",
    "                delivery_date_to=end_date.strftime(\"%Y-%m-%d\"),\n",
    "                settlement_point=hub,\n",
    "                size=2000,\n",
    "                page=page,\n",
    "            )\n",
    "\n",
    "            if 'data' in spp_data and 'records' in spp_data['data']:\n",
    "                records = spp_data['data']['records']\n",
    "                if not records:\n",
    "                    break\n",
    "\n",
    "                fields = spp_data.get('fields', [])\n",
    "                field_names = [f['name'] for f in fields]\n",
    "                day_df = pd.DataFrame(records, columns=field_names)\n",
    "                hub_df_list.append(day_df)\n",
    "\n",
    "                meta = spp_data.get('_meta', {})\n",
    "                total_pages = meta.get('totalPages', 1)\n",
    "                current_page = meta.get('currentPage', page)\n",
    "\n",
    "                if current_page >= total_pages:\n",
    "                    break\n",
    "                page += 1\n",
    "            else:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching {hub}: {e}\")\n",
    "            break\n",
    "\n",
    "    if hub_df_list:\n",
    "        hub_df = pd.concat(hub_df_list, ignore_index=True)\n",
    "        df_spp_list.append(hub_df)\n",
    "        print(f\"âœ“ {len(hub_df)} records\")\n",
    "    else:\n",
    "        print(\"âœ— No data\")\n",
    "\n",
    "df_spp = pd.concat(df_spp_list, ignore_index=True) if df_spp_list else pd.DataFrame()\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Total Settlement Point Prices: {len(df_spp):,} records\")\n",
    "\n",
    "# Process the data\n",
    "if len(df_spp) > 0:\n",
    "    # Convert date and hour columns\n",
    "    df_spp['deliveryDate'] = pd.to_datetime(df_spp['deliveryDate'])\n",
    "    df_spp['hourEnding'] = df_spp['hourEnding'].str.split(':').str[0].astype(int)\n",
    "    df_spp['settlementPointPrice'] = pd.to_numeric(df_spp['settlementPointPrice'], errors='coerce')\n",
    "\n",
    "    # Create hub_prices dataframe\n",
    "    hub_prices = df_spp.copy()\n",
    "    hub_prices.rename(columns={'settlementPoint': 'busName', 'settlementPointPrice': 'lmp'}, inplace=True)\n",
    "\n",
    "    # Remove any duplicate records\n",
    "    hub_prices = hub_prices.drop_duplicates(subset=['deliveryDate', 'hourEnding', 'busName'])\n",
    "\n",
    "    # Comprehensive statistics\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DATA SUMMARY\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Hub price records: {len(hub_prices):,}\")\n",
    "    print(f\"Date range: {hub_prices['deliveryDate'].min().strftime('%Y-%m-%d')} to {hub_prices['deliveryDate'].max().strftime('%Y-%m-%d')}\")\n",
    "    print(f\"Unique dates: {hub_prices['deliveryDate'].nunique()}\")\n",
    "    print(f\"Unique hubs: {hub_prices['busName'].nunique()}\")\n",
    "    print(f\"Hubs: {', '.join(sorted(hub_prices['busName'].unique()))}\")\n",
    "\n",
    "    # Hours per day statistics\n",
    "    hours_per_day = hub_prices.groupby(['deliveryDate', 'busName'])['hourEnding'].nunique()\n",
    "    print(f\"\\nHours per day (avg): {hours_per_day.mean():.1f}\")\n",
    "    print(f\"Hours per day (min): {hours_per_day.min()}\")\n",
    "    print(f\"Hours per day (max): {hours_per_day.max()}\")\n",
    "\n",
    "    # Price statistics by hub\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"PRICE STATISTICS BY HUB\")\n",
    "    print(f\"{'='*60}\")\n",
    "    hub_stats = hub_prices.groupby('busName')['lmp'].agg([\n",
    "        ('count', 'count'),\n",
    "        ('mean', 'mean'),\n",
    "        ('std', 'std'),\n",
    "        ('min', 'min'),\n",
    "        ('max', 'max'),\n",
    "        ('median', 'median'),\n",
    "    ]).round(2)\n",
    "    hub_stats['range'] = hub_stats['max'] - hub_stats['min']\n",
    "    hub_stats['cv'] = (hub_stats['std'] / hub_stats['mean'] * 100).round(2)  # Coefficient of variation\n",
    "    print(hub_stats.to_string())\n",
    "\n",
    "    # Daily spread statistics\n",
    "    daily_spreads = hub_prices.groupby(['deliveryDate', 'busName']).agg(\n",
    "        min_price=('lmp', 'min'),\n",
    "        max_price=('lmp', 'max'),\n",
    "        avg_price=('lmp', 'mean'),\n",
    "    ).reset_index()\n",
    "    daily_spreads['spread'] = daily_spreads['max_price'] - daily_spreads['min_price']\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DAILY ARBITRAGE SPREAD STATISTICS\")\n",
    "    print(f\"{'='*60}\")\n",
    "    spread_stats = daily_spreads.groupby('busName')['spread'].agg([\n",
    "        ('mean', 'mean'),\n",
    "        ('std', 'std'),\n",
    "        ('min', 'min'),\n",
    "        ('max', 'max'),\n",
    "        ('median', 'median'),\n",
    "    ]).round(2)\n",
    "    print(spread_stats.to_string())\n",
    "\n",
    "    # Verify data completeness\n",
    "    if hours_per_day.min() < 20:\n",
    "        print(\"\\nâš ï¸ Warning: Some days have fewer than 20 hours. Data may be incomplete.\")\n",
    "else:\n",
    "    hub_prices = pd.DataFrame()\n",
    "    daily_spreads = pd.DataFrame()\n",
    "    print(\"âš ï¸ No pricing data available\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arbitrage Spread Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(hub_prices) > 0 and 'lmp' in hub_prices.columns and 'deliveryDate' in hub_prices.columns:\n",
    "    # Calculate daily spreads (reuse from cell 3 if available, otherwise recalculate)\n",
    "    if 'daily_spreads' not in locals():\n",
    "        daily_spreads = hub_prices.groupby(['deliveryDate', 'busName']).agg(\n",
    "            min_price=('lmp', 'min'),\n",
    "            max_price=('lmp', 'max'),\n",
    "            avg_price=('lmp', 'mean'),\n",
    "        ).reset_index()\n",
    "        daily_spreads['spread'] = daily_spreads['max_price'] - daily_spreads['min_price']\n",
    "\n",
    "    # Get top hubs by average spread (best arbitrage opportunities)\n",
    "    top_hubs = daily_spreads.groupby('busName')['spread'].mean().sort_values(ascending=False).head(3).index.tolist()\n",
    "    main_hub = top_hubs[0] if top_hubs else hub_prices['busName'].iloc[0]\n",
    "\n",
    "    # Create datetime column\n",
    "    hub_prices['datetime'] = hub_prices['deliveryDate'] + pd.to_timedelta(hub_prices['hourEnding'], unit='h')\n",
    "\n",
    "    # Multi-hub comparison visualization\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        subplot_titles=(\n",
    "            'Hourly Prices - Top 3 Hubs (Best Arbitrage)',\n",
    "            'Daily Arbitrage Spread by Hub',\n",
    "            'Hub Price Comparison (Last 7 Days)'\n",
    "        ),\n",
    "        vertical_spacing=0.1,\n",
    "        row_heights=[0.4, 0.3, 0.3]\n",
    "    )\n",
    "\n",
    "    # Colors for hubs\n",
    "    hub_colors = {\n",
    "        'HB_HOUSTON': '#00d4aa',\n",
    "        'HB_NORTH': '#74b9ff',\n",
    "        'HB_SOUTH': '#ff6b6b',\n",
    "        'HB_WEST': '#ffd93d',\n",
    "        'HB_PAN': '#a29bfe',\n",
    "        'HB_BUSAVG': '#fd79a8',\n",
    "        'HB_HUBAVG': '#00cec9',\n",
    "    }\n",
    "\n",
    "    # Plot top 3 hubs hourly prices\n",
    "    for hub in top_hubs[:3]:\n",
    "        hub_data = hub_prices[hub_prices['busName'] == hub].sort_values(['datetime'])\n",
    "        color = hub_colors.get(hub, '#888888')\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=hub_data['datetime'], y=hub_data['lmp'],\n",
    "            mode='lines', name=hub,\n",
    "            line={\"color\": color, \"width\": 1.5},\n",
    "            legendgroup='prices'\n",
    "        ), row=1, col=1)\n",
    "\n",
    "    # Plot daily spreads for all hubs\n",
    "    for hub in sorted(daily_spreads['busName'].unique()):\n",
    "        hub_spreads = daily_spreads[daily_spreads['busName'] == hub].sort_values('deliveryDate')\n",
    "        color = hub_colors.get(hub, '#888888')\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=hub_spreads['deliveryDate'], y=hub_spreads['spread'],\n",
    "            mode='lines+markers', name=f'{hub} Spread',\n",
    "            line={\"color\": color, \"width\": 1.5},\n",
    "            marker={\"size\": 4},\n",
    "            legendgroup='spreads'\n",
    "        ), row=2, col=1)\n",
    "\n",
    "    # Box plot comparing hubs (last 7 days)\n",
    "    recent_dates = hub_prices['deliveryDate'].max() - pd.Timedelta(days=7)\n",
    "    recent_prices = hub_prices[hub_prices['deliveryDate'] >= recent_dates]\n",
    "\n",
    "    for hub in sorted(recent_prices['busName'].unique()):\n",
    "        hub_data = recent_prices[recent_prices['busName'] == hub]['lmp']\n",
    "        color = hub_colors.get(hub, '#888888')\n",
    "        fig.add_trace(go.Box(\n",
    "            y=hub_data, name=hub,\n",
    "            marker_color=color,\n",
    "            boxmean='sd',\n",
    "            legendgroup='box'\n",
    "        ), row=3, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=900, template='plotly_dark', showlegend=True,\n",
    "        title_text=\"<b>Multi-Hub Battery Arbitrage Analysis</b><br><sup>Comparing pricing across ERCOT hubs</sup>\",\n",
    "        font={\"family\": 'Inter, sans-serif'},\n",
    "        legend={\"orientation\": 'h', \"yanchor\": 'bottom', \"y\": -0.15}\n",
    "    )\n",
    "    fig.update_yaxes(title_text=\"$/MWh\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"Spread $/MWh\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"Price $/MWh\", row=3, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date/Time\", row=1, col=1)\n",
    "    fig.update_xaxes(title_text=\"Date\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Hub\", row=3, col=1)\n",
    "    fig.show()\n",
    "\n",
    "    # Print summary statistics\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"ARBITRAGE OPPORTUNITY RANKING\")\n",
    "    print(f\"{'='*60}\")\n",
    "    spread_ranking = daily_spreads.groupby('busName')['spread'].agg(['mean', 'std', 'max']).sort_values('mean', ascending=False)\n",
    "    spread_ranking.columns = ['Avg Spread ($/MWh)', 'Std Dev', 'Max Spread ($/MWh)']\n",
    "    print(spread_ranking.round(2).to_string())\n",
    "else:\n",
    "    print(\"âš ï¸ No price data available.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hub Correlation Analysis\n",
    "\n",
    "Understanding price relationships between hubs helps identify arbitrage opportunities and regional price differences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(hub_prices) > 0 and hub_prices['busName'].nunique() > 1:\n",
    "    # Create pivot table: dates/hours as index, hubs as columns\n",
    "    price_pivot = hub_prices.pivot_table(\n",
    "        index=['deliveryDate', 'hourEnding'],\n",
    "        columns='busName',\n",
    "        values='lmp',\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    correlation_matrix = price_pivot.corr()\n",
    "\n",
    "    # Create heatmap\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=correlation_matrix.values,\n",
    "        x=correlation_matrix.columns,\n",
    "        y=correlation_matrix.index,\n",
    "        colorscale=[[0, '#1a1a2e'], [0.5, '#0f3460'], [1, '#00d4aa']],\n",
    "        colorbar={\"title\": 'Correlation'},\n",
    "        text=correlation_matrix.values.round(3),\n",
    "        texttemplate='%{text}',\n",
    "        textfont={\"size\": 10}\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"<b>Hub Price Correlation Matrix</b><br><sup>Higher correlation = similar price movements</sup>\",\n",
    "        xaxis_title=\"Hub\", yaxis_title=\"Hub\",\n",
    "        template='plotly_dark', height=500,\n",
    "        font={\"family\": 'Inter, sans-serif'}\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "    # Calculate price differences (spreads between hubs)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"HUB-TO-HUB PRICE SPREADS (Average)\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    hub_means = price_pivot.mean().sort_values(ascending=False)\n",
    "    print(\"\\nAverage Prices by Hub:\")\n",
    "    for hub, price in hub_means.items():\n",
    "        print(f\"  {hub}: ${price:.2f}/MWh\")\n",
    "\n",
    "    # Find hub pairs with largest average spread\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"TOP HUB PAIRS FOR ARBITRAGE\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    spreads = []\n",
    "    for i, hub1 in enumerate(hub_means.index):\n",
    "        for hub2 in hub_means.index[i+1:]:\n",
    "            spread = abs(hub_means[hub1] - hub_means[hub2])\n",
    "            spreads.append({\n",
    "                'Hub1': hub1,\n",
    "                'Hub2': hub2,\n",
    "                'Avg Spread': spread,\n",
    "                'Correlation': correlation_matrix.loc[hub1, hub2]\n",
    "            })\n",
    "\n",
    "    spread_df = pd.DataFrame(spreads).sort_values('Avg Spread', ascending=False).head(10)\n",
    "    print(spread_df.to_string(index=False))\n",
    "\n",
    "    # Hourly spread analysis\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"HOURLY SPREAD PATTERNS\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    if len(hub_means) >= 2:\n",
    "        highest_hub = hub_means.index[0]\n",
    "        lowest_hub = hub_means.index[-1]\n",
    "\n",
    "        hourly_spread = price_pivot[highest_hub] - price_pivot[lowest_hub]\n",
    "        hourly_spread_by_hour = hourly_spread.groupby(level='hourEnding').mean()\n",
    "\n",
    "        print(f\"\\nAverage hourly spread: {highest_hub} - {lowest_hub}\")\n",
    "        print(f\"  Max spread hour: {hourly_spread_by_hour.idxmax()} ({hourly_spread_by_hour.max():.2f} $/MWh)\")\n",
    "        print(f\"  Min spread hour: {hourly_spread_by_hour.idxmin()} ({hourly_spread_by_hour.min():.2f} $/MWh)\")\n",
    "        print(f\"  Average spread: {hourly_spread_by_hour.mean():.2f} $/MWh\")\n",
    "else:\n",
    "    print(\"âš ï¸ Need data from multiple hubs for correlation analysis.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimal Charge/Discharge Windows\n",
    "\n",
    "When should a battery charge vs discharge? Analyze typical hourly price patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(hub_prices) > 0:\n",
    "    # Analyze hourly patterns across all hubs\n",
    "    main_hub = 'HB_HOUSTON' if 'HB_HOUSTON' in hub_prices['busName'].values else hub_prices['busName'].iloc[0]\n",
    "    main_hub_data = hub_prices[hub_prices['busName'] == main_hub]\n",
    "\n",
    "    # Average price by hour for main hub\n",
    "    hourly_pattern = main_hub_data.groupby('hourEnding')['lmp'].agg(['mean', 'std', 'min', 'max']).reset_index()\n",
    "    avg_price = hourly_pattern['mean'].mean()\n",
    "\n",
    "    # Classify hours\n",
    "    hourly_pattern['action'] = hourly_pattern['mean'].apply(\n",
    "        lambda x: 'CHARGE' if x < avg_price * 0.85 else ('DISCHARGE' if x > avg_price * 1.15 else 'HOLD')\n",
    "    )\n",
    "\n",
    "    # Calculate price range (max - min) per hour\n",
    "    hourly_pattern['price_range'] = hourly_pattern['max'] - hourly_pattern['min']\n",
    "\n",
    "    colors = {'CHARGE': '#00d4aa', 'DISCHARGE': '#ff6b6b', 'HOLD': '#666666'}\n",
    "\n",
    "    fig = make_subplots(\n",
    "        rows=2, cols=1,\n",
    "        subplot_titles=(\n",
    "            f'Optimal Battery Dispatch Schedule - {main_hub}',\n",
    "            'Hourly Price Volatility (Range)'\n",
    "        ),\n",
    "        vertical_spacing=0.15\n",
    "    )\n",
    "\n",
    "    # Price bars by action\n",
    "    for action in ['CHARGE', 'HOLD', 'DISCHARGE']:\n",
    "        mask = hourly_pattern['action'] == action\n",
    "        fig.add_trace(go.Bar(\n",
    "            x=hourly_pattern[mask]['hourEnding'], y=hourly_pattern[mask]['mean'],\n",
    "            name=action, marker_color=colors[action],\n",
    "            error_y={\"type\": 'data', \"array\": hourly_pattern[mask]['std'], \"visible\": True, \"color\": 'rgba(255,255,255,0.3)'},\n",
    "            legendgroup='price'\n",
    "        ), row=1, col=1)\n",
    "\n",
    "    # Price range (volatility)\n",
    "    fig.add_trace(go.Bar(\n",
    "        x=hourly_pattern['hourEnding'], y=hourly_pattern['price_range'],\n",
    "        name='Price Range', marker_color='#ffd93d',\n",
    "        legendgroup='volatility'\n",
    "    ), row=2, col=1)\n",
    "\n",
    "    fig.add_hline(y=avg_price, line_dash=\"dash\", line_color=\"white\",\n",
    "                  annotation_text=f\"Avg: ${avg_price:.2f}\", row=1, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"<b>Battery Dispatch Strategy</b><br><sup>{main_hub} - Based on {len(main_hub_data)} hourly observations</sup>\",\n",
    "        xaxis_title=\"Hour of Day\", yaxis_title=\"Avg LMP ($/MWh)\",\n",
    "        template='plotly_dark', barmode='overlay', height=600,\n",
    "        legend={\"orientation\": 'h', \"yanchor\": 'bottom', \"y\": -0.15},\n",
    "        font={\"family\": 'Inter, sans-serif'}\n",
    "    )\n",
    "    fig.update_yaxes(title_text=\"Price Range ($/MWh)\", row=2, col=1)\n",
    "    fig.update_xaxes(title_text=\"Hour of Day\", row=2, col=1)\n",
    "    fig.show()\n",
    "\n",
    "    # Print detailed schedule\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"RECOMMENDED DISPATCH SCHEDULE - {main_hub}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    charge_hours = sorted(hourly_pattern[hourly_pattern['action']=='CHARGE']['hourEnding'].tolist())\n",
    "    discharge_hours = sorted(hourly_pattern[hourly_pattern['action']=='DISCHARGE']['hourEnding'].tolist())\n",
    "    hold_hours = sorted(hourly_pattern[hourly_pattern['action']=='HOLD']['hourEnding'].tolist())\n",
    "\n",
    "    print(f\"\\nCHARGE Hours ({len(charge_hours)}): {charge_hours}\")\n",
    "    print(f\"  Avg Price: ${hourly_pattern[hourly_pattern['action']=='CHARGE']['mean'].mean():.2f}/MWh\")\n",
    "    print(f\"\\nDISCHARGE Hours ({len(discharge_hours)}): {discharge_hours}\")\n",
    "    print(f\"  Avg Price: ${hourly_pattern[hourly_pattern['action']=='DISCHARGE']['mean'].mean():.2f}/MWh\")\n",
    "    print(f\"\\nHOLD Hours ({len(hold_hours)}): {hold_hours}\")\n",
    "\n",
    "    # Best arbitrage windows\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"BEST ARBITRAGE WINDOWS (Charge Low, Discharge High)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    best_charge = hourly_pattern.nsmallest(4, 'mean')[['hourEnding', 'mean']]\n",
    "    best_discharge = hourly_pattern.nlargest(4, 'mean')[['hourEnding', 'mean']]\n",
    "    print(\"\\nTop 4 CHARGE Hours:\")\n",
    "    for _, row in best_charge.iterrows():\n",
    "        print(f\"  Hour {row['hourEnding']:2d}: ${row['mean']:.2f}/MWh\")\n",
    "    print(\"\\nTop 4 DISCHARGE Hours:\")\n",
    "    for _, row in best_discharge.iterrows():\n",
    "        print(f\"  Hour {row['hourEnding']:2d}: ${row['mean']:.2f}/MWh\")\n",
    "\n",
    "    potential_spread = best_discharge['mean'].mean() - best_charge['mean'].mean()\n",
    "    print(f\"\\nPotential Spread: ${potential_spread:.2f}/MWh\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. System Load by Weather Zone\n",
    "\n",
    "Understanding load patterns helps retail providers manage portfolios and predict demand.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch actual system load for December 2024\n",
    "load_data = ercot.get_actual_system_load_by_weather_zone(\n",
    "    operating_day_from=start_date.strftime(\"%Y-%m-%d\"),\n",
    "    operating_day_to=end_date.strftime(\"%Y-%m-%d\"),\n",
    "    size=2000,\n",
    ")\n",
    "\n",
    "df_load = pd.DataFrame(load_data.get('records', []))\n",
    "print(f\"Load records: {len(df_load)}\")\n",
    "\n",
    "if len(df_load) > 0:\n",
    "    df_load['datetime'] = pd.to_datetime(df_load['operatingDay'].astype(str) + ' ' + df_load['hourEnding'].astype(str).str.zfill(2) + ':00:00')\n",
    "    df_load = df_load.sort_values('datetime')\n",
    "\n",
    "    zones = ['coast', 'east', 'farWest', 'north', 'northC', 'southern', 'southC', 'west']\n",
    "    available_zones = [z for z in zones if z in df_load.columns]\n",
    "    for z in available_zones:\n",
    "        df_load[z] = pd.to_numeric(df_load[z], errors='coerce')\n",
    "\n",
    "    zone_colors = {\n",
    "        'coast': '#00d4aa', 'east': '#74b9ff', 'farWest': '#ffd93d',\n",
    "        'north': '#ff6b6b', 'northC': '#a29bfe', 'southern': '#fd79a8',\n",
    "        'southC': '#00cec9', 'west': '#e17055'\n",
    "    }\n",
    "\n",
    "    fig = go.Figure()\n",
    "    for zone in available_zones:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_load['datetime'], y=df_load[zone],\n",
    "            name=zone.upper(), mode='lines', stackgroup='one',\n",
    "            line={\"width\": 0.5, \"color\": zone_colors.get(zone, '#888')},\n",
    "        ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"<b>ERCOT System Load by Weather Zone</b>\",\n",
    "        xaxis_title=\"Date/Time\", yaxis_title=\"Load (MW)\",\n",
    "        template='plotly_dark', height=450, hovermode='x unified',\n",
    "        legend={\"orientation\": 'h', \"yanchor\": 'bottom', \"y\": 1.02},\n",
    "        font={\"family\": 'Inter, sans-serif'}\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Price Volatility Heatmap\n",
    "\n",
    "High volatility = opportunity for batteries, risk for retailers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(hub_prices) > 0:\n",
    "    hub_prices['dayOfWeek'] = hub_prices['deliveryDate'].dt.dayofweek\n",
    "\n",
    "    # Calculate volatility by day of week and hour\n",
    "    volatility = hub_prices.groupby(['dayOfWeek', 'hourEnding'])['lmp'].std().reset_index()\n",
    "    volatility_pivot = volatility.pivot(index='dayOfWeek', columns='hourEnding', values='lmp')\n",
    "\n",
    "    day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "    fig = go.Figure(data=go.Heatmap(\n",
    "        z=volatility_pivot.values,\n",
    "        x=volatility_pivot.columns,\n",
    "        y=day_names,\n",
    "        colorscale=[[0, '#1a1a2e'], [0.5, '#0f3460'], [1, '#ff6b6b']],\n",
    "        colorbar={\"title\": 'Std Dev $/MWh'}\n",
    "    ))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=\"<b>Price Volatility Heatmap</b><br><sup>When are prices most unpredictable?</sup>\",\n",
    "        xaxis_title=\"Hour\", yaxis_title=\"Day\",\n",
    "        template='plotly_dark', height=350,\n",
    "        font={\"family\": 'Inter, sans-serif'}\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Battery Revenue Estimation\n",
    "\n",
    "Estimate potential revenue for a 100 MW / 400 MWh battery system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(hub_prices) > 0:\n",
    "    # Battery parameters\n",
    "    BATTERY_MW = 100   # Power\n",
    "    BATTERY_MWH = 400  # Energy (4-hour)\n",
    "    EFFICIENCY = 0.88  # Round-trip\n",
    "\n",
    "    # Simple arbitrage: charge during 4 lowest hours, discharge during 4 highest\n",
    "    daily_revenue = []\n",
    "    for date in hub_prices['deliveryDate'].unique():\n",
    "        day_prices = hub_prices[hub_prices['deliveryDate'] == date].sort_values('lmp')\n",
    "        if len(day_prices) >= 8:\n",
    "            charge_cost = day_prices.head(4)['lmp'].sum() * BATTERY_MW\n",
    "            discharge_rev = day_prices.tail(4)['lmp'].sum() * BATTERY_MW * EFFICIENCY\n",
    "            daily_revenue.append({\n",
    "                'date': date,\n",
    "                'net_revenue': discharge_rev - charge_cost,\n",
    "                'avg_charge': day_prices.head(4)['lmp'].mean(),\n",
    "                'avg_discharge': day_prices.tail(4)['lmp'].mean()\n",
    "            })\n",
    "\n",
    "    df_rev = pd.DataFrame(daily_revenue)\n",
    "\n",
    "    if len(df_rev) > 0:\n",
    "        fig = make_subplots(rows=2, cols=1,\n",
    "            subplot_titles=('Daily Net Revenue', 'Charge vs Discharge Prices'),\n",
    "            vertical_spacing=0.15)\n",
    "\n",
    "        colors = ['#00d4aa' if x >= 0 else '#ff6b6b' for x in df_rev['net_revenue']]\n",
    "        fig.add_trace(go.Bar(x=df_rev['date'], y=df_rev['net_revenue'], marker_color=colors), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(x=df_rev['date'], y=df_rev['avg_charge'], name='Charge', line={\"color\": '#00d4aa'}), row=2, col=1)\n",
    "        fig.add_trace(go.Scatter(x=df_rev['date'], y=df_rev['avg_discharge'], name='Discharge', line={\"color\": '#ff6b6b'}), row=2, col=1)\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"<b>Battery Revenue</b><br><sup>{BATTERY_MW}MW/{BATTERY_MWH}MWh, {EFFICIENCY*100:.0f}% efficiency</sup>\",\n",
    "            template='plotly_dark', height=500, showlegend=True,\n",
    "            legend={\"orientation\": 'h', \"yanchor\": 'bottom', \"y\": 1.02},\n",
    "            font={\"family\": 'Inter, sans-serif'}\n",
    "        )\n",
    "        fig.update_yaxes(title_text=\"$\", row=1, col=1)\n",
    "        fig.update_yaxes(title_text=\"$/MWh\", row=2, col=1)\n",
    "        fig.show()\n",
    "\n",
    "        print(f\"\\nðŸ’° Revenue Summary ({BATTERY_MW}MW / {BATTERY_MWH}MWh)\")\n",
    "        print(f\"   Total: ${df_rev['net_revenue'].sum():,.0f}\")\n",
    "        print(f\"   Daily Avg: ${df_rev['net_revenue'].mean():,.0f}\")\n",
    "        print(f\"   Best Day: ${df_rev['net_revenue'].max():,.0f}\")\n",
    "        print(f\"   Annualized: ${df_rev['net_revenue'].mean() * 365:,.0f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Renewable Generation Patterns\n",
    "\n",
    "Solar and wind patterns drive price dynamics. Critical for battery timing and retail hedging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch solar and wind data\n",
    "solar_data = ercot.get_spp_hourly_average_actual_forecast(size=500)\n",
    "wind_data = ercot.get_wpp_hourly_average_actual_forecast(size=500)\n",
    "\n",
    "df_solar = pd.DataFrame(solar_data.get('records', []))\n",
    "df_wind = pd.DataFrame(wind_data.get('records', []))\n",
    "\n",
    "print(f\"Solar: {len(df_solar)} records, Wind: {len(df_wind)} records\")\n",
    "\n",
    "if len(df_solar) > 0 and len(df_wind) > 0:\n",
    "    # Process solar\n",
    "    if 'operatingDay' in df_solar.columns and 'hourEnding' in df_solar.columns:\n",
    "        df_solar['datetime'] = pd.to_datetime(df_solar['operatingDay'].astype(str) + ' ' + df_solar['hourEnding'].astype(str).str.zfill(2) + ':00:00')\n",
    "        df_solar = df_solar.sort_values('datetime')\n",
    "\n",
    "    # Process wind\n",
    "    if 'operatingDay' in df_wind.columns and 'hourEnding' in df_wind.columns:\n",
    "        df_wind['datetime'] = pd.to_datetime(df_wind['operatingDay'].astype(str) + ' ' + df_wind['hourEnding'].astype(str).str.zfill(2) + ':00:00')\n",
    "        df_wind = df_wind.sort_values('datetime')\n",
    "\n",
    "    fig = make_subplots(rows=2, cols=1,\n",
    "        subplot_titles=('Solar Generation (MW)', 'Wind Generation (MW)'),\n",
    "        vertical_spacing=0.1)\n",
    "\n",
    "    if 'systemWide' in df_solar.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_solar['datetime'], y=pd.to_numeric(df_solar['systemWide'], errors='coerce'),\n",
    "            name='Solar', line={\"color\": '#ffd93d', \"width\": 2},\n",
    "            fill='tozeroy', fillcolor='rgba(255, 217, 61, 0.3)'\n",
    "        ), row=1, col=1)\n",
    "\n",
    "    if 'systemWide' in df_wind.columns:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_wind['datetime'], y=pd.to_numeric(df_wind['systemWide'], errors='coerce'),\n",
    "            name='Wind', line={\"color\": '#74b9ff', \"width\": 2},\n",
    "            fill='tozeroy', fillcolor='rgba(116, 185, 255, 0.3)'\n",
    "        ), row=2, col=1)\n",
    "\n",
    "    fig.update_layout(\n",
    "        height=500, template='plotly_dark',\n",
    "        title_text=\"<b>Renewable Generation</b>\",\n",
    "        font={\"family\": 'Inter, sans-serif'},\n",
    "        showlegend=False\n",
    "    )\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "**Battery Storage:**\n",
    "- Price spread analysis for arbitrage revenue\n",
    "- Optimal charge/discharge scheduling\n",
    "- Revenue modeling with efficiency losses\n",
    "\n",
    "**Retail Electricity:**\n",
    "- Load patterns by weather zone\n",
    "- Price volatility for risk assessment\n",
    "- Renewable generation patterns\n",
    "\n",
    "All powered by the Tiny Grid SDK with just a few lines of code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
